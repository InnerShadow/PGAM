{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import collections\n",
    "import scipy.stats\n",
    "import statistics\n",
    "from Bio import SeqIO\n",
    "from itertools import product\n",
    "from scipy.fftpack import fft, ifft\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def headerNAC(k, foutput):\n",
    "    global listTotal, caracteres\n",
    "    listTotal = []\n",
    "    file = open(foutput, 'a')\n",
    "    file.write('%s,' % ('nameseq'))\n",
    "    permsList = [''.join(str(i) for i in x) for x in product(caracteres, repeat=k)]\n",
    "    # print (permsList)\n",
    "    for perm in permsList:\n",
    "        # print (perm)\n",
    "        listTotal.append(perm)\n",
    "        file.write('%s,' % (str(perm)))\n",
    "    file.write('label')\n",
    "    file.write('\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "def chunks(seq, win, step):\n",
    "    seqlen = len(seq)\n",
    "    for i in range(0, seqlen, step):\n",
    "        j = seqlen if i+win>seqlen else i+win\n",
    "        yield seq[i:j]\n",
    "        if j==seqlen: break\n",
    "    return        \n",
    "    \n",
    "\n",
    "def chunks_two(seq, win):\n",
    "    seqlen = len(seq)\n",
    "    for i in range(seqlen):\n",
    "        j = seqlen if i+win>seqlen else i+win\n",
    "        yield seq[i:j]\n",
    "        if j==seqlen: break\n",
    "    return\n",
    "\n",
    "            \n",
    "def file_record(name_seq, foutput, labelDataset):\n",
    "    file = open(foutput, 'a')\n",
    "    file.write('%s,' % (name_seq))\n",
    "    for x in probabilities:\n",
    "        # print (x)\n",
    "        file.write('%s,' % (str(x[1])))\n",
    "    file.write(labelDataset)\n",
    "    file.write('\\n')\n",
    "    print ('Recorded Sequence: %s' % (name_seq))\n",
    "    return\n",
    "    \n",
    "\n",
    "# Nucleic acid composition (NAC), Di-nucleotide composition (DNC), Tri-nucleotide composition (TNC)\n",
    "def nacSeq(k, foutput, finput, labelDataset):\n",
    "    global probabilities\n",
    "    headerNAC(k, foutput)\n",
    "    for seq_record in SeqIO.parse(finput, 'fasta'):\n",
    "        seq = seq_record.seq\n",
    "        seq = seq.upper()\t\n",
    "        name_seq = seq_record.name\n",
    "        probabilities = []\n",
    "        kmer = {}\n",
    "        totalWindows = (len(seq) - k) + 1 # (L - k + 1)\n",
    "        permsList = [''.join(str(i) for i in x) for x in product(caracteres, repeat=k)]\n",
    "        for key in permsList:\n",
    "            kmer[key] = 0\n",
    "        kmer = collections.OrderedDict(sorted(kmer.items()))\n",
    "        for subseq in chunks_two(seq, k):\n",
    "            if subseq in kmer:\n",
    "                # print(subseq)\n",
    "                kmer[subseq] = kmer[subseq] + 1\n",
    "            else:\n",
    "                kmer[subseq] = 1\n",
    "        for key, value in kmer.items():\n",
    "            # print (key)\n",
    "            # print (value)\n",
    "            probabilities.append([str(key), value/totalWindows])\n",
    "        file_record(name_seq, foutput, labelDataset)\n",
    "    return\n",
    "\n",
    "\n",
    "def ExtractionTechniques(finput, foutput, tech):\n",
    "    global listTotal, caracteres, complement\n",
    "    labelDataset = 'DNA'\n",
    "    # tech = str(args.type)\n",
    "    seq = 1\n",
    "    stepw = 1\n",
    "    if seq == 1:\n",
    "        caracteres = ['A', 'C', 'G', 'T']\n",
    "        complement = {'A': 'T','C': 'G','G': 'C','T': 'A'}\n",
    "    else:\n",
    "        caracteres = ['A', 'C', 'G', 'U']\n",
    "        complement = {'A': 'U','C': 'G','G': 'C','U': 'A'}\n",
    "    if tech == 'NAC' or tech == 'nac':\n",
    "        nacSeq(1, foutput, finput, labelDataset)\n",
    "    elif tech == 'DNC' or tech == 'dnc':\n",
    "        nacSeq(2, foutput, finput, labelDataset)\n",
    "    elif tech == 'TNC' or tech == 'tnc':\n",
    "        nacSeq(3, foutput, finput, labelDataset)\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(foutput):\n",
    "\tdataset = open(foutput, 'a')\n",
    "\tdataset.write(\"nameseq,average,median,maximum,minimum,peak,\"\n",
    "                  + \"none_levated_peak,sample_standard_deviation,population_standard_deviation,\"\n",
    "                  + \"percentile15,percentile25,percentile50,percentile75,amplitude,\"\n",
    "                  + \"variance,interquartile_range,semi_interquartile_range,\"\n",
    "                  + \"coefficient_of_variation,skewness,kurtosis,label\")\n",
    "\tdataset.write(\"\\n\")\n",
    "\treturn\n",
    "\n",
    "        \n",
    "def file_record(foutput, label_dataset):\n",
    "    dataset = open(foutput, 'a')\n",
    "    dataset.write(\"%s,\" % (str(name_seq)))\n",
    "    for metric in features:\n",
    "        dataset.write(\"%s,\" % (metric))\n",
    "        # dataset.write(\"{0:.4f},\".format(metric))\n",
    "    dataset.write(label_dataset)\n",
    "    dataset.write(\"\\n\")\n",
    "    print(\"Sequence Analyzed!!\")\n",
    "    return\n",
    "\n",
    "\n",
    "def feature_extraction():\n",
    "    global features\n",
    "    features = []\n",
    "    average = sum(spectrum)/len(spectrum)\n",
    "    features.append(average)\n",
    "    ###################################\n",
    "    median = np.median(spectrum)\n",
    "    features.append(median)\n",
    "\t###################################\n",
    "    maximum = np.max(spectrum)\n",
    "    features.append(maximum)\n",
    "    ###################################\n",
    "    minimum = np.min(spectrum)\n",
    "    features.append(minimum)\n",
    "    ###################################\n",
    "    peak = (len(spectrum)/3)/(average)\n",
    "    features.append(peak)\n",
    "    ###################################\n",
    "    peak_two = (len(spectrumTwo)/3)/(np.mean(spectrumTwo))\n",
    "    features.append(peak_two)\n",
    "    ###################################\n",
    "    standard_deviation = np.std(spectrum) # standard deviation\n",
    "    features.append(standard_deviation)\n",
    "    ###################################\n",
    "    standard_deviation_pop = statistics.stdev(spectrum) # population sample standard deviation \n",
    "    features.append(standard_deviation_pop)\n",
    "    ###################################\n",
    "    percentile15 = np.percentile(spectrum, 15)\n",
    "    features.append(percentile15)\n",
    "    ###################################\n",
    "    percentile25 = np.percentile(spectrum, 25)\n",
    "    features.append(percentile25)\n",
    "    ###################################\n",
    "    percentile50 = np.percentile(spectrum, 50)\n",
    "    features.append(percentile50)\n",
    "    ###################################\n",
    "    percentile75 = np.percentile(spectrum, 75)\n",
    "    features.append(percentile75)\n",
    "    ###################################\n",
    "    amplitude = maximum - minimum\n",
    "    features.append(amplitude)\n",
    "    ###################################\n",
    "    # mode = statistics.mode(spectrum)\n",
    "    ###################################\n",
    "    variance = statistics.variance(spectrum)\n",
    "    features.append(variance)\n",
    "    ###################################\n",
    "    interquartile_range = np.percentile(spectrum, 75) - np.percentile(spectrum, 25)\n",
    "    features.append(interquartile_range)\n",
    "    ###################################\n",
    "    semi_interquartile_range = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25))/2 \n",
    "    features.append(semi_interquartile_range)\n",
    "    ###################################\n",
    "    coefficient_of_variation = standard_deviation/average\n",
    "    features.append(coefficient_of_variation)\n",
    "    ###################################\n",
    "    skewness = (3 * (average - median))/standard_deviation\n",
    "    features.append(skewness)   \n",
    "    ###################################\n",
    "    kurtosis = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25)) / (2 * (np.percentile(spectrum, 90) - np.percentile(spectrum, 10))) \n",
    "    features.append(kurtosis)\n",
    "    ###################################\n",
    "    return\n",
    "\n",
    "\n",
    "def real_fourier(finput, foutput, label_dataset):\n",
    "    header(foutput)\n",
    "    global spectrum, spectrumTwo, name_seq\n",
    "    for seq_record in SeqIO.parse(finput, \"fasta\"):\n",
    "        seq = seq_record.seq\n",
    "        seq = seq.upper()\n",
    "        name_seq = seq_record.name\n",
    "        spectrum = []\n",
    "        spectrumTwo = []\n",
    "        real = []\n",
    "        for nucle in seq:\n",
    "            if nucle == \"T\" or nucle == \"U\":\n",
    "                real.append(1.5)\n",
    "            elif nucle == \"C\":\n",
    "                real.append(0.5)\n",
    "            elif nucle == \"A\":\n",
    "                real.append(-1.5)\n",
    "            else:\n",
    "                real.append(-0.5)\n",
    "        FR = fft(real)\n",
    "        for i in range(len(seq)):\n",
    "            specTotal = (abs(FR[i])**2)\n",
    "            specTwo = (abs(FR[i]))\n",
    "            spectrum.append(specTotal)\n",
    "            spectrumTwo.append(specTwo)\n",
    "        feature_extraction()\n",
    "        file_record(foutput, label_dataset)\n",
    "    return\n",
    "\n",
    "\n",
    "#############################################################################    \n",
    "def FourierClass(finput, foutput, label_dataset):\n",
    "    real_fourier(finput, foutput, label_dataset)\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EntropyClass_header(foutput, ksize):\n",
    "    file = open(foutput, 'a')\n",
    "    file.write(\"nameseq,\")\n",
    "    for i in range(1, ksize+1):\n",
    "        file.write(\"k\" + str(i) + \",\")\n",
    "    file.write(\"label\")\n",
    "    file.write(\"\\n\")\n",
    "    return\n",
    "\n",
    "\n",
    "def EntropyClass_chunks_two(seq, win):\n",
    "    seqlen = len(seq)\n",
    "    for i in range(seqlen):\n",
    "        j = seqlen if i+win>seqlen else i+win\n",
    "        yield seq[i:j]\n",
    "        if j==seqlen: break\n",
    "    return\n",
    "\n",
    "            \n",
    "def EntropyClass_file_record(foutput, label_dataset):\n",
    "    file = open(foutput, 'a')\n",
    "    file.write(\"%s,\" % (name_seq))\n",
    "    for data in information_entropy:\n",
    "        file.write(\"%s,\" % (str(data)))\n",
    "    file.write(label_dataset)\n",
    "    file.write(\"\\n\")\n",
    "    print (\"Recorded Sequence!!!\")\n",
    "    return\n",
    "    \n",
    "\n",
    "def entropy_equation(ksize, finput, foutput, e, label_dataset):\n",
    "    EntropyClass_header(foutput, ksize)\n",
    "    global name_seq, information_entropy\n",
    "    for seq_record in SeqIO.parse(finput, \"fasta\"):\n",
    "        seq = seq_record.seq\n",
    "        seq = seq.upper()\n",
    "        name_seq = seq_record.name\n",
    "        information_entropy = []\n",
    "        for k in range(1, ksize+1):\n",
    "            probabilities = []\n",
    "            kmer = {}\n",
    "            total_windows = (len(seq) - k) + 1 # (L - k + 1)\n",
    "            for subseq in EntropyClass_chunks_two(seq, k):\n",
    "                if subseq in kmer:\n",
    "                    # print(subseq)\n",
    "                    kmer[subseq] = kmer[subseq] + 1\n",
    "                else:\n",
    "                    kmer[subseq] = 1\n",
    "            for key, value in kmer.items():\n",
    "                # print(key)\n",
    "                # print(value)\n",
    "                probabilities.append(value/total_windows)\n",
    "            if e == \"Shannon\" or e == \"shannon\":\n",
    "                entropy_equation = [(p * math.log(p, 2)) for p in probabilities]\n",
    "                entropy = -(sum(entropy_equation))\n",
    "                information_entropy.append(entropy)\n",
    "            else:\n",
    "                q = 2\n",
    "                entropy_equation = [(p ** q) for p in probabilities]\n",
    "                entropy =  (1/(q - 1)) * (1 - sum(entropy_equation))\n",
    "                information_entropy.append(entropy)\n",
    "        EntropyClass_file_record(foutput, label_dataset)\n",
    "    return\n",
    "\n",
    "        \n",
    "#############################################################################    \n",
    "def EntropyClass(finput, foutput):\n",
    "    ksize = 10\n",
    "    stepw = 1\n",
    "    e = 'Shannon'\n",
    "    label_dataset = 'mRNA'\n",
    "    entropy_equation(ksize, finput, foutput, e, label_dataset)\n",
    "       \n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n"
     ]
    }
   ],
   "source": [
    "# ExtractionTechniques(\"res.fasta\", 'res_1.csv', 'dnc')\n",
    "# ExtractionTechniques(\"res.fasta\", 'res_1.csv', 'tnc')\n",
    "# FourierClass(\"res.fasta\", 'res_1.csv', 'mRNA')\n",
    "# EntropyClass(\"res.fasta\", 'res_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PGAMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
