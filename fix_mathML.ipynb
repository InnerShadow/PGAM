{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import collections\n",
    "import scipy.stats\n",
    "import statistics\n",
    "from Bio import SeqIO\n",
    "from itertools import product\n",
    "from scipy.fftpack import fft, ifft\n",
    "import math \n",
    "\n",
    "import operator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ExtractionTechniques_headerNAC(k, foutput):\n",
    "    global listTotal, caracteres\n",
    "    listTotal = []\n",
    "    file = open(foutput, 'a')\n",
    "    file.write('%s,' % ('nameseq'))\n",
    "    permsList = [''.join(str(i) for i in x) for x in product(caracteres, repeat=k)]\n",
    "    # print (permsList)\n",
    "    for perm in permsList:\n",
    "        # print (perm)\n",
    "        listTotal.append(perm)\n",
    "        file.write('%s,' % (str(perm)))\n",
    "    file.write('label')\n",
    "    file.write('\\n')\n",
    "    return\n",
    "\n",
    "\n",
    "def ExtractionTechniques_chunks(seq, win, step):\n",
    "    seqlen = len(seq)\n",
    "    for i in range(0, seqlen, step):\n",
    "        j = seqlen if i+win>seqlen else i+win\n",
    "        yield seq[i:j]\n",
    "        if j==seqlen: break\n",
    "    return        \n",
    "    \n",
    "\n",
    "def ExtractionTechniques_chunks_two(seq, win):\n",
    "    seqlen = len(seq)\n",
    "    for i in range(seqlen):\n",
    "        j = seqlen if i+win>seqlen else i+win\n",
    "        yield seq[i:j]\n",
    "        if j==seqlen: break\n",
    "    return\n",
    "\n",
    "            \n",
    "def ExtractionTechniques_file_record(name_seq, foutput, labelDataset):\n",
    "    file = open(foutput, 'a')\n",
    "    file.write('%s,' % (name_seq))\n",
    "    for x in probabilities:\n",
    "        # print (x)\n",
    "        file.write('%s,' % (str(x[1])))\n",
    "    file.write(labelDataset)\n",
    "    file.write('\\n')\n",
    "    print ('Recorded Sequence: %s' % (name_seq))\n",
    "    return\n",
    "    \n",
    "\n",
    "# Nucleic acid composition (NAC), Di-nucleotide composition (DNC), Tri-nucleotide composition (TNC)\n",
    "def nacSeq(k, foutput, finput, labelDataset):\n",
    "    global probabilities\n",
    "    ExtractionTechniques_headerNAC(k, foutput)\n",
    "    for seq_record in SeqIO.parse(finput, 'fasta'):\n",
    "        seq = seq_record.seq\n",
    "        seq = seq.upper()\t\n",
    "        name_seq = seq_record.name\n",
    "        probabilities = []\n",
    "        kmer = {}\n",
    "        totalWindows = (len(seq) - k) + 1 # (L - k + 1)\n",
    "        permsList = [''.join(str(i) for i in x) for x in product(caracteres, repeat=k)]\n",
    "        for key in permsList:\n",
    "            kmer[key] = 0\n",
    "        kmer = collections.OrderedDict(sorted(kmer.items()))\n",
    "        for subseq in ExtractionTechniques_chunks_two(seq, k):\n",
    "            if subseq in kmer:\n",
    "                # print(subseq)\n",
    "                kmer[subseq] = kmer[subseq] + 1\n",
    "            else:\n",
    "                kmer[subseq] = 1\n",
    "        for key, value in kmer.items():\n",
    "            # print (key)\n",
    "            # print (value)\n",
    "            probabilities.append([str(key), value/totalWindows])\n",
    "        ExtractionTechniques_file_record(name_seq, foutput, labelDataset)\n",
    "    return\n",
    "\n",
    "\n",
    "def ExtractionTechniques(finput, foutput, tech):\n",
    "    global listTotal, caracteres, complement\n",
    "    labelDataset = 'DNA'\n",
    "    # tech = str(args.type)\n",
    "    seq = 1\n",
    "    stepw = 1\n",
    "    if seq == 1:\n",
    "        caracteres = ['A', 'C', 'G', 'T']\n",
    "        complement = {'A': 'T','C': 'G','G': 'C','T': 'A'}\n",
    "    else:\n",
    "        caracteres = ['A', 'C', 'G', 'U']\n",
    "        complement = {'A': 'U','C': 'G','G': 'C','U': 'A'}\n",
    "    if tech == 'NAC' or tech == 'nac':\n",
    "        nacSeq(1, foutput, finput, labelDataset)\n",
    "    elif tech == 'DNC' or tech == 'dnc':\n",
    "        nacSeq(2, foutput, finput, labelDataset)\n",
    "    elif tech == 'TNC' or tech == 'tnc':\n",
    "        nacSeq(3, foutput, finput, labelDataset)\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(foutput):\n",
    "\tdataset = open(foutput, 'a')\n",
    "\tdataset.write(\"nameseq,average,median,maximum,minimum,peak,\"\n",
    "                  + \"none_levated_peak,sample_standard_deviation,population_standard_deviation,\"\n",
    "                  + \"percentile15,percentile25,percentile50,percentile75,amplitude,\"\n",
    "                  + \"variance,interquartile_range,semi_interquartile_range,\"\n",
    "                  + \"coefficient_of_variation,skewness,kurtosis,label\")\n",
    "\tdataset.write(\"\\n\")\n",
    "\treturn\n",
    "\n",
    "        \n",
    "def file_record(foutput, label_dataset):\n",
    "    dataset = open(foutput, 'a')\n",
    "    dataset.write(\"%s,\" % (str(name_seq)))\n",
    "    for metric in features:\n",
    "        dataset.write(\"%s,\" % (metric))\n",
    "        # dataset.write(\"{0:.4f},\".format(metric))\n",
    "    dataset.write(label_dataset)\n",
    "    dataset.write(\"\\n\")\n",
    "    print(\"Sequence Analyzed!!\")\n",
    "    return\n",
    "\n",
    "\n",
    "def feature_extraction():\n",
    "    global features\n",
    "    features = []\n",
    "    average = sum(spectrum)/len(spectrum)\n",
    "    features.append(average)\n",
    "    ###################################\n",
    "    median = np.median(spectrum)\n",
    "    features.append(median)\n",
    "\t###################################\n",
    "    maximum = np.max(spectrum)\n",
    "    features.append(maximum)\n",
    "    ###################################\n",
    "    minimum = np.min(spectrum)\n",
    "    features.append(minimum)\n",
    "    ###################################\n",
    "    peak = (len(spectrum)/3)/(average)\n",
    "    features.append(peak)\n",
    "    ###################################\n",
    "    peak_two = (len(spectrumTwo)/3)/(np.mean(spectrumTwo))\n",
    "    features.append(peak_two)\n",
    "    ###################################\n",
    "    standard_deviation = np.std(spectrum) # standard deviation\n",
    "    features.append(standard_deviation)\n",
    "    ###################################\n",
    "    standard_deviation_pop = statistics.stdev(spectrum) # population sample standard deviation \n",
    "    features.append(standard_deviation_pop)\n",
    "    ###################################\n",
    "    percentile15 = np.percentile(spectrum, 15)\n",
    "    features.append(percentile15)\n",
    "    ###################################\n",
    "    percentile25 = np.percentile(spectrum, 25)\n",
    "    features.append(percentile25)\n",
    "    ###################################\n",
    "    percentile50 = np.percentile(spectrum, 50)\n",
    "    features.append(percentile50)\n",
    "    ###################################\n",
    "    percentile75 = np.percentile(spectrum, 75)\n",
    "    features.append(percentile75)\n",
    "    ###################################\n",
    "    amplitude = maximum - minimum\n",
    "    features.append(amplitude)\n",
    "    ###################################\n",
    "    # mode = statistics.mode(spectrum)\n",
    "    ###################################\n",
    "    variance = statistics.variance(spectrum)\n",
    "    features.append(variance)\n",
    "    ###################################\n",
    "    interquartile_range = np.percentile(spectrum, 75) - np.percentile(spectrum, 25)\n",
    "    features.append(interquartile_range)\n",
    "    ###################################\n",
    "    semi_interquartile_range = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25))/2 \n",
    "    features.append(semi_interquartile_range)\n",
    "    ###################################\n",
    "    coefficient_of_variation = standard_deviation/average\n",
    "    features.append(coefficient_of_variation)\n",
    "    ###################################\n",
    "    skewness = (3 * (average - median))/standard_deviation\n",
    "    features.append(skewness)   \n",
    "    ###################################\n",
    "    kurtosis = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25)) / (2 * (np.percentile(spectrum, 90) - np.percentile(spectrum, 10))) \n",
    "    features.append(kurtosis)\n",
    "    ###################################\n",
    "    return\n",
    "\n",
    "\n",
    "def real_fourier(finput, foutput, label_dataset):\n",
    "    header(foutput)\n",
    "    global spectrum, spectrumTwo, name_seq\n",
    "    for seq_record in SeqIO.parse(finput, \"fasta\"):\n",
    "        seq = seq_record.seq\n",
    "        seq = seq.upper()\n",
    "        name_seq = seq_record.name\n",
    "        spectrum = []\n",
    "        spectrumTwo = []\n",
    "        real = []\n",
    "        for nucle in seq:\n",
    "            if nucle == \"T\" or nucle == \"U\":\n",
    "                real.append(1.5)\n",
    "            elif nucle == \"C\":\n",
    "                real.append(0.5)\n",
    "            elif nucle == \"A\":\n",
    "                real.append(-1.5)\n",
    "            else:\n",
    "                real.append(-0.5)\n",
    "        FR = fft(real)\n",
    "        for i in range(len(seq)):\n",
    "            specTotal = (abs(FR[i])**2)\n",
    "            specTwo = (abs(FR[i]))\n",
    "            spectrum.append(specTotal)\n",
    "            spectrumTwo.append(specTwo)\n",
    "        feature_extraction()\n",
    "        file_record(foutput, label_dataset)\n",
    "    return\n",
    "\n",
    "\n",
    "#############################################################################    \n",
    "def FourierClass(finput, foutput, label_dataset):\n",
    "    real_fourier(finput, foutput, label_dataset)\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EntropyClass_header(foutput, ksize):\n",
    "    file = open(foutput, 'a')\n",
    "    file.write(\"nameseq,\")\n",
    "    for i in range(1, ksize+1):\n",
    "        file.write(\"k\" + str(i) + \",\")\n",
    "    file.write(\"label\")\n",
    "    file.write(\"\\n\")\n",
    "    return\n",
    "\n",
    "\n",
    "def EntropyClass_chunks_two(seq, win):\n",
    "    seqlen = len(seq)\n",
    "    for i in range(seqlen):\n",
    "        j = seqlen if i+win>seqlen else i+win\n",
    "        yield seq[i:j]\n",
    "        if j==seqlen: break\n",
    "    return\n",
    "\n",
    "            \n",
    "def EntropyClass_file_record(foutput, label_dataset):\n",
    "    file = open(foutput, 'a')\n",
    "    file.write(\"%s,\" % (name_seq))\n",
    "    for data in information_entropy:\n",
    "        file.write(\"%s,\" % (str(data)))\n",
    "    file.write(label_dataset)\n",
    "    file.write(\"\\n\")\n",
    "    print (\"Recorded Sequence!!!\")\n",
    "    return\n",
    "    \n",
    "\n",
    "def entropy_equation(ksize, finput, foutput, e, label_dataset):\n",
    "    EntropyClass_header(foutput, ksize)\n",
    "    global name_seq, information_entropy\n",
    "    for seq_record in SeqIO.parse(finput, \"fasta\"):\n",
    "        seq = seq_record.seq\n",
    "        seq = seq.upper()\n",
    "        name_seq = seq_record.name\n",
    "        information_entropy = []\n",
    "        for k in range(1, ksize+1):\n",
    "            probabilities = []\n",
    "            kmer = {}\n",
    "            total_windows = (len(seq) - k) + 1 # (L - k + 1)\n",
    "            for subseq in EntropyClass_chunks_two(seq, k):\n",
    "                if subseq in kmer:\n",
    "                    # print(subseq)\n",
    "                    kmer[subseq] = kmer[subseq] + 1\n",
    "                else:\n",
    "                    kmer[subseq] = 1\n",
    "            for key, value in kmer.items():\n",
    "                # print(key)\n",
    "                # print(value)\n",
    "                probabilities.append(value/total_windows)\n",
    "            if e == \"Shannon\" or e == \"shannon\":\n",
    "                entropy_equation = [(p * math.log(p, 2)) for p in probabilities]\n",
    "                entropy = -(sum(entropy_equation))\n",
    "                information_entropy.append(entropy)\n",
    "            else:\n",
    "                q = 2\n",
    "                entropy_equation = [(p ** q) for p in probabilities]\n",
    "                entropy =  (1/(q - 1)) * (1 - sum(entropy_equation))\n",
    "                information_entropy.append(entropy)\n",
    "        EntropyClass_file_record(foutput, label_dataset)\n",
    "    return\n",
    "\n",
    "        \n",
    "#############################################################################    \n",
    "def EntropyClass(finput, foutput):\n",
    "    ksize = 10\n",
    "    stepw = 1\n",
    "    e = 'Shannon'\n",
    "    label_dataset = 'mRNA'\n",
    "    entropy_equation(ksize, finput, foutput, e, label_dataset)\n",
    "       \n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AccumulatedNucleotideFrequency_check_files(dataset_labels):\n",
    "    for name, label in dataset_labels.items():\n",
    "        if os.path.exists(name):\n",
    "            print('Dataset %s: Found File' % (name))\n",
    "            run = 1\n",
    "        else:\n",
    "            print('Dataset %s: File not exists' % (name))\n",
    "            run = 0\n",
    "            break\n",
    "    return run\n",
    "\n",
    "def AccumulatedNucleotideFrequency_header_fourier(foutput):\n",
    "    dataset = open(foutput, 'a')\n",
    "    dataset.write('nameseq,average,median,maximum,minimum,peak,'\n",
    "                  + 'none_levated_peak,sample_standard_deviation,population_standard_deviation,'\n",
    "                  + 'percentile15,percentile25,percentile50,percentile75,amplitude,'\n",
    "                  + 'variance,interquartile_range,semi_interquartile_range,'\n",
    "                  + 'coefficient_of_variation,skewness,kurtosis,label')\n",
    "    dataset.write('\\n')\n",
    "    return foutput\n",
    "\n",
    "\n",
    "def AccumulatedNucleotideFrequency_file_record_fourier(features, name_seq, label_dataset, foutput):\n",
    "    dataset = open(foutput, 'a')\n",
    "    dataset.write('%s,' % (str(name_seq)))\n",
    "    for metric in features:\n",
    "        dataset.write('%s,' % (metric))\n",
    "        # dataset.write('{0:.4f},'.format(metric))\n",
    "    dataset.write(label_dataset)\n",
    "    dataset.write('\\n')\n",
    "    print('Recorded Sequence: %s' % (name_seq))\n",
    "    return\n",
    "\n",
    "\n",
    "def AccumulatedNucleotideFrequency_feature_extraction(features, spectrum, spectrumTwo):\n",
    "    average = sum(spectrum)/len(spectrum)\n",
    "    features.append(average)\n",
    "    ###################################\n",
    "    median = np.median(spectrum)\n",
    "    features.append(median)\n",
    "\t###################################\n",
    "    maximum = np.max(spectrum)\n",
    "    features.append(maximum)\n",
    "    ###################################\n",
    "    minimum = np.min(spectrum)\n",
    "    features.append(minimum)\n",
    "    ###################################\n",
    "    peak = (len(spectrum)/3)/(average)\n",
    "    features.append(peak)\n",
    "    ###################################\n",
    "    peak_two = (len(spectrumTwo)/3)/(np.mean(spectrumTwo))\n",
    "    features.append(peak_two)\n",
    "    ###################################\n",
    "    standard_deviation = np.std(spectrum) # standard deviation\n",
    "    features.append(standard_deviation)\n",
    "    ###################################\n",
    "    standard_deviation_pop = statistics.stdev(spectrum) # population sample standard deviation \n",
    "    features.append(standard_deviation_pop)\n",
    "    ###################################\n",
    "    percentile15 = np.percentile(spectrum, 15)\n",
    "    features.append(percentile15)\n",
    "    ###################################\n",
    "    percentile25 = np.percentile(spectrum, 25)\n",
    "    features.append(percentile25)\n",
    "    ###################################\n",
    "    percentile50 = np.percentile(spectrum, 50)\n",
    "    features.append(percentile50)\n",
    "    ###################################\n",
    "    percentile75 = np.percentile(spectrum, 75)\n",
    "    features.append(percentile75)\n",
    "    ###################################\n",
    "    amplitude = maximum - minimum\n",
    "    features.append(amplitude)\n",
    "    ###################################\n",
    "    # mode = statistics.mode(spectrum)\n",
    "    ###################################\n",
    "    variance = statistics.variance(spectrum)\n",
    "    features.append(variance)\n",
    "    ###################################\n",
    "    interquartile_range = np.percentile(spectrum, 75) - np.percentile(spectrum, 25)\n",
    "    features.append(interquartile_range)\n",
    "    ###################################\n",
    "    semi_interquartile_range = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25))/2 \n",
    "    features.append(semi_interquartile_range)\n",
    "    ###################################\n",
    "    coefficient_of_variation = standard_deviation/average\n",
    "    features.append(coefficient_of_variation)\n",
    "    ###################################\n",
    "    skewness = (3 * (average - median))/standard_deviation\n",
    "    features.append(skewness)   \n",
    "    ###################################\n",
    "    kurtosis = (np.percentile(spectrum, 75) - np.percentile(spectrum, 25)) / (2 * (np.percentile(spectrum, 90) - np.percentile(spectrum, 10))) \n",
    "    features.append(kurtosis)\n",
    "    ###################################\n",
    "    return\n",
    "\n",
    "\n",
    "def AccumulatedNucleotideFrequency_accumulated_nucle_frequency_fourier(dataset_labels, foutput):\n",
    "    AccumulatedNucleotideFrequency_header_fourier(foutput)\n",
    "    for finput, label in dataset_labels.items():\n",
    "        for seq_record in SeqIO.parse(finput, 'fasta'):\n",
    "            seq = seq_record.seq\n",
    "            seq = seq.upper()\n",
    "            name_seq = seq_record.name\n",
    "            features = []\n",
    "            spectrum = []\n",
    "            spectrumTwo = []\n",
    "            mapping = []\n",
    "            A = 0\n",
    "            C = 0\n",
    "            T = 0\n",
    "            G = 0\n",
    "            for i in range(len(seq)):\n",
    "                if seq[i] == 'A':\n",
    "                    A += 1\n",
    "                    mapping.append(A / (i + 1))\n",
    "                elif seq[i] == 'C':\n",
    "                    C += 1\n",
    "                    mapping.append(C / (i + 1))\n",
    "                elif seq[i] == 'T' or seq[i] == 'U':\n",
    "                    T += 1\n",
    "                    mapping.append(T / (i + 1))\n",
    "                else:\n",
    "                    G += 1\n",
    "                    mapping.append(G / (i + 1))\n",
    "            Fmap = fft(mapping)\n",
    "            for i in range(len(mapping)):\n",
    "                specTotal = (abs(Fmap[i])**2)\n",
    "                specTwo = (abs(Fmap[i]))\n",
    "                spectrum.append(specTotal)\n",
    "                spectrumTwo.append(specTwo)\n",
    "            AccumulatedNucleotideFrequency_feature_extraction(features, spectrum, spectrumTwo)\n",
    "            AccumulatedNucleotideFrequency_file_record_fourier(features, name_seq, label, foutput)\n",
    "    return\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#############################################################################   \n",
    "def AccumulatedNucleotideFrequency(name, foutput, label):\n",
    "    n = 1\n",
    "    dataset_labels = {}\n",
    "    for i in range(1, n + 1):\n",
    "        dataset_labels[name] = label\n",
    "    if AccumulatedNucleotideFrequency_check_files(dataset_labels) == 1:\n",
    "        AccumulatedNucleotideFrequency_accumulated_nucle_frequency_fourier(dataset_labels, foutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def des_start_code(codes):\n",
    "\tif codes in ('ATG', 'AUG'):\n",
    "\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "\n",
    "def des_end_code(codes):\n",
    "\tif codes in ('TAA', 'UAA', 'TAG', 'UAG', 'TGA', 'UGA'):\n",
    "\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "\n",
    "def read_by_three(string, offset):\n",
    "\tflag = True\n",
    "\tlength = len(string)\n",
    "\tstart = end = -1\n",
    "\ti = 0\n",
    "\tresult = set()\n",
    "\twhile i < length-2:\n",
    "\t\tcodes = string[i:i+3]\n",
    "\t\tif des_start_code(codes) and flag:\n",
    "\t\t\tstart = i\n",
    "\t\t\tflag = False\n",
    "\t\tif des_end_code(codes) and not flag:\n",
    "\t\t\tend = i + 2\n",
    "\t\t\tflag = True\n",
    "\t\tif (end > start) and (start != -1):\n",
    "\t\t\tresult.add((start + offset, end + offset))\n",
    "\t\ti = i + 3\n",
    "\treturn result\n",
    "\n",
    "\n",
    "def get_gc(string):\n",
    "\tgc = ((string.count('G') + string.count('C')) / len(string)) * 100\n",
    "\treturn gc\n",
    "\n",
    "\n",
    "def get_info(string, pos):\n",
    "\tlength = pos[1] - pos[0] + 1\n",
    "\tgc = get_gc(string[pos[0]:pos[1]+1])\n",
    "\treturn str(pos[0]), str(pos[1]), str(length), str(gc)\n",
    "\n",
    "\n",
    "def orf(seq):\n",
    "\tresult_info = []\n",
    "\tstrings = [seq, seq[1:], seq[2:]]\n",
    "\tfor index, string in enumerate(strings):\n",
    "\t\t# print(index)\n",
    "\t\t# print(string)\n",
    "\t\tpositions = read_by_three(string, index)\n",
    "\t\tpositions = sorted(positions, key=operator.itemgetter(0))\n",
    "\t\t# print(positions)\n",
    "\t\tfor pos in positions:\n",
    "\t\t\tresult_info.append(get_info(seq, pos))\n",
    "\t# print(result_info)\n",
    "\t# print(len(result_info))\n",
    "\treturn result_info\n",
    "\n",
    "\n",
    "def run(finput, foutput, label_dataset):\n",
    "\tfile = open(foutput, 'a')\n",
    "\tfile.write('nameseq,maximum_ORF_length,minimum_ORF_length,std_ORF_length,average_ORF_length,cv_ORF_length,' + ''\n",
    "\t\t\t   + 'maximum_GC_content_ORF,minimum_GC_content_ORF,std_GC_content_ORF,' + ''\n",
    "\t\t\t   + 'average_GC_content_ORF,cv_GC_content_ORF,label')\n",
    "\tfile.write('\\n')\n",
    "\tfor seq_record in SeqIO.parse(finput, 'fasta'):\n",
    "\t\tseq = seq_record.seq\n",
    "\t\tseq = seq.upper()\n",
    "\t\tname_seq = seq_record.name\n",
    "\t\tfile.write('%s,' % name_seq)\n",
    "\t\tmeasures = orf(seq)\n",
    "\t\tif len(measures) > 0:\n",
    "\t\t\tlength_orf = []\n",
    "\t\t\tgc_mea = []\n",
    "\t\t\tfor values in measures:\n",
    "\t\t\t\tlength_orf.append(int(values[2]))\n",
    "\t\t\t\tgc_mea.append(float(values[3]))\n",
    "\t\t\t# print(length_orf)\n",
    "\t\t\t# print(gc_mea)\n",
    "\t\t\tfile.write('%s,' % max(length_orf))\n",
    "\t\t\tfile.write('%s,' % min(length_orf))\n",
    "\t\t\tfile.write('%s,' % np.std(length_orf))\n",
    "\t\t\tfile.write('%s,' % np.mean(length_orf))\n",
    "\t\t\tfile.write('%s,' % scipy.stats.variation(length_orf))\n",
    "\t\t\tfile.write('%s,' % max(gc_mea))\n",
    "\t\t\tfile.write('%s,' % min(gc_mea))\n",
    "\t\t\tfile.write('%s,' % np.std(gc_mea))\n",
    "\t\t\tfile.write('%s,' % np.mean(gc_mea))\n",
    "\t\t\tfile.write('%s,' % scipy.stats.variation(gc_mea))\n",
    "\t\t\tfile.write('%s' % label_dataset)\n",
    "\t\t\tfile.write('\\n')\n",
    "\t\telse:\n",
    "\t\t\tfile.write('0,0,0,0,0,0,0,0,0,0,')\n",
    "\t\t\tfile.write('%s' % label_dataset)\n",
    "\t\t\tfile.write('\\n')\n",
    "\t\tprint('Recorded Sequence: %s' % name_seq)\n",
    "\treturn\n",
    "\n",
    "\n",
    "\n",
    "def CodingClass(finput, foutput, label_dataset):\n",
    "\tstart_time = time.time()\n",
    "\trun(finput, foutput, label_dataset)\n",
    "\tprint('Computation time %s senconds' % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_up_position_prob(value, base, position_para, position_prob, position_weight):\n",
    "\n",
    "\t\"\"\"look up positional probability by base and value\"\"\"\n",
    "\n",
    "\tif float(value) < 0:\n",
    "\t\treturn None\n",
    "\tfor idx, val in enumerate(position_para):\n",
    "\t\tif float(value) >= val:\n",
    "\t\t\treturn float(position_prob[base][idx]) * float(position_weight[base])\n",
    "\n",
    "\n",
    "def look_up_content_prob(value, base, content_para, content_prob, content_weight):\n",
    "\n",
    "\t\"\"\"look up content probability by base and value\"\"\"\n",
    "\n",
    "\tif float(value) < 0:\n",
    "\t\treturn None\n",
    "\tfor idx, val in enumerate(content_para):\n",
    "\t\tif float(value) >= val:\n",
    "\t\t\treturn float(content_prob[base][idx]) * float(content_weight[base])\n",
    "\n",
    "\n",
    "def fickett_value_orf(seq, type_seq):\n",
    "\n",
    "\t\"\"\"calculate Fickett value. Input is DNA sequence\"\"\"\n",
    "\n",
    "\tposition_prob = {\n",
    "\t\t'A': [0.94, 0.68, 0.84, 0.93, 0.58, 0.68, 0.45, 0.34, 0.20, 0.22],\n",
    "\t\t'C': [0.80, 0.70, 0.70, 0.81, 0.66, 0.48, 0.51, 0.33, 0.30, 0.23],\n",
    "\t\t'G': [0.90, 0.88, 0.74, 0.64, 0.53, 0.48, 0.27, 0.16, 0.08, 0.08],\n",
    "\t\t'T': [0.97, 0.97, 0.91, 0.68, 0.69, 0.44, 0.54, 0.20, 0.09, 0.09]}\n",
    "\n",
    "\tposition_weight = {'A': 0.26, 'C': 0.18, 'G': 0.31, 'T': 0.33}\n",
    "\tposition_para = [1.9, 1.8, 1.7, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 0.0]\n",
    "\n",
    "\tcontent_prob = {\n",
    "\t\t'A': [0.28, 0.49, 0.44, 0.55, 0.62, 0.49, 0.67, 0.65, 0.81, 0.21],\n",
    "\t\t'C': [0.82, 0.64, 0.51, 0.64, 0.59, 0.59, 0.43, 0.44, 0.39, 0.31],\n",
    "\t\t'G': [0.40, 0.54, 0.47, 0.64, 0.64, 0.73, 0.41, 0.41, 0.33, 0.29],\n",
    "\t\t'T': [0.28, 0.24, 0.39, 0.40, 0.55, 0.75, 0.56, 0.69, 0.51, 0.58]}\n",
    "\n",
    "\tcontent_weight = {'A': 0.11, 'C': 0.12, 'G': 0.15, 'T': 0.14}\n",
    "\tcontent_para = [0.33, 0.31, 0.29, 0.27, 0.25, 0.23, 0.21, 0.17, 0]\n",
    "\n",
    "\tif len(seq) < 2:\n",
    "\t\treturn 0\n",
    "\tfickett_score = 0\n",
    "\tseq = seq.upper()\n",
    "\ttotal_base = len(seq)\n",
    "\tA_content = float(seq.count('A')) / total_base\n",
    "\tC_content = float(seq.count('C')) / total_base\n",
    "\tG_content = float(seq.count('G')) / total_base\n",
    "\tif type_seq == 1:\n",
    "\t\tT_content = float(seq.count('T')) / total_base\n",
    "\telse:\n",
    "\t\tT_content = float(seq.count('U')) / total_base\n",
    "\n",
    "\tphase_0 = [seq[i] for i in range(0, len(seq)) if i % 3 == 0]\n",
    "\tphase_1 = [seq[i] for i in range(0, len(seq)) if i % 3 == 1]\n",
    "\tphase_2 = [seq[i] for i in range(0, len(seq)) if i % 3 == 2]\n",
    "\t\n",
    "\tA_position = max(phase_0.count('A'), phase_1.count('A'), phase_2.count('A')) / (min(phase_0.count('A'), phase_1.count('A'), phase_2.count('A')) + 1.0)\n",
    "\n",
    "\tC_position = max(phase_0.count('C'), phase_1.count('C'), phase_2.count('C')) / (min(phase_0.count('C'), phase_1.count('C'), phase_2.count('C')) + 1.0)\n",
    "\n",
    "\tG_position = max(phase_0.count('G'), phase_1.count('G'), phase_2.count('G')) / (min(phase_0.count('G'), phase_1.count('G'), phase_2.count('G')) + 1.0)\n",
    "\n",
    "\tif type_seq == 1:\n",
    "\t\tT_position = max(phase_0.count('T'), phase_1.count('T'), phase_2.count('T')) / (min(phase_0.count('T'), phase_1.count('T'), phase_2.count('T')) + 1.0)\n",
    "\telse:\n",
    "\t\tT_position = max(phase_0.count('U'), phase_1.count('U'), phase_2.count('U')) / (min(phase_0.count('U'), phase_1.count('U'), phase_2.count('U')) + 1.0)\n",
    "\n",
    "\tfickett_score += look_up_content_prob(A_content, 'A', content_para, content_prob, content_weight)\n",
    "\tfickett_score += look_up_content_prob(C_content, 'C', content_para, content_prob, content_weight)\n",
    "\tfickett_score += look_up_content_prob(G_content, 'G', content_para, content_prob, content_weight)\n",
    "\tfickett_score += look_up_content_prob(T_content, 'T', content_para, content_prob, content_weight)\n",
    "\t\n",
    "\tfickett_score += look_up_position_prob(A_position, 'A', position_para, position_prob, position_weight)\n",
    "\tfickett_score += look_up_position_prob(C_position, 'C', position_para, position_prob, position_weight)\n",
    "\tfickett_score += look_up_position_prob(G_position, 'G', position_para, position_prob, position_weight)\n",
    "\tfickett_score += look_up_position_prob(T_position, 'T', position_para, position_prob, position_weight)\n",
    "\t\n",
    "\treturn fickett_score\n",
    "\n",
    "\n",
    "def fickett_value_full_sequence(seq, type_seq):\n",
    "\n",
    "\t\"\"\"calculate Fickett from full sequence - CPC2\"\"\"\n",
    "\n",
    "\tposition_para = [1.9, 1.8, 1.7, 1.6, 1.5, 1.4, 1.3, 1.2, 1.1, 0.0]\n",
    "\tcontent_para = [0.33, 0.31, 0.29, 0.27, 0.25, 0.23, 0.21, 0.19, 0.17, 0]\n",
    "\n",
    "\tposition_prob = {\n",
    "\t\t'A': [0.51, 0.55, 0.57, 0.52, 0.48, 0.58, 0.57, 0.54, 0.50, 0.36],\n",
    "\t\t'C': [0.29, 0.44, 0.55, 0.49, 0.52, 0.60, 0.60, 0.56, 0.51, 0.38],\n",
    "\t\t'G': [0.62, 0.67, 0.74, 0.65, 0.61, 0.62, 0.52, 0.41, 0.31, 0.17],\n",
    "\t\t'T': [0.51, 0.60, 0.69, 0.64, 0.62, 0.67, 0.58, 0.48, 0.39, 0.24]}\n",
    "\t\n",
    "\tposition_weight = {'A': 0.062, 'C': 0.093, 'G': 0.205, 'T': 0.154}\n",
    "\tcontent_weight = {'A': 0.084, 'C': 0.076, 'G': 0.081, 'T': 0.055}\n",
    "\n",
    "\tcontent_prob = {\n",
    "\t\t'A': [0.40, 0.55, 0.58, 0.58, 0.52, 0.48, 0.45, 0.45, 0.38, 0.19],\n",
    "\t\t'C': [0.50, 0.63, 0.59, 0.50, 0.46, 0.45, 0.47, 0.56, 0.59, 0.33],\n",
    "\t\t'G': [0.21, 0.40, 0.47, 0.50, 0.52, 0.56, 0.57, 0.52, 0.44, 0.23],\n",
    "\t\t'T': [0.30, 0.49, 0.56, 0.53, 0.48, 0.48, 0.52, 0.57, 0.60, 0.51]}\n",
    "\n",
    "\tif len(seq) < 2:\n",
    "\t\treturn 0\n",
    "\n",
    "\tfickett_score = 0\n",
    "\tseq = seq.upper()\n",
    "\ttotal_base = len(seq)\n",
    "\n",
    "\tphase_0 = seq[::3]\n",
    "\tphase_1 = seq[1::3]\n",
    "\tphase_2 = seq[2::3]\n",
    "\n",
    "\tphase_0_A = phase_0.count('A')\n",
    "\tphase_1_A = phase_1.count('A')\n",
    "\tphase_2_A = phase_2.count('A')\n",
    "\tphase_0_C = phase_0.count('C')\n",
    "\tphase_1_C = phase_1.count('C')\n",
    "\tphase_2_C = phase_2.count('C')\n",
    "\tphase_0_G = phase_0.count('G')\n",
    "\tphase_1_G = phase_1.count('G')\n",
    "\tphase_2_G = phase_2.count('G')\n",
    "\tif type_seq == 1:\n",
    "\t\tphase_0_T = phase_0.count('T')\n",
    "\t\tphase_1_T = phase_1.count('T')\n",
    "\t\tphase_2_T = phase_2.count('T')\n",
    "\telse:\n",
    "\t\tphase_0_T = phase_0.count('U')\n",
    "\t\tphase_1_T = phase_1.count('U')\n",
    "\t\tphase_2_T = phase_2.count('U')\n",
    "\n",
    "\tA_content = float(phase_0_A + phase_1_A + phase_2_A) / total_base\n",
    "\tC_content = float(phase_0_C + phase_1_C + phase_2_C) / total_base\n",
    "\tG_content = float(phase_0_G + phase_1_G + phase_2_G) / total_base\n",
    "\tT_content = float(phase_0_T + phase_1_T + phase_2_T) / total_base\n",
    "\tA_position = max([phase_0_A, phase_1_A, phase_2_A]) / (min([phase_0_A, phase_1_A, phase_2_A]) + 1.0)\n",
    "\tC_position = max([phase_0_C, phase_1_C, phase_2_C]) / (min([phase_0_C, phase_1_C, phase_2_C]) + 1.0)\n",
    "\tG_position = max([phase_0_G, phase_1_G, phase_2_G]) / (min([phase_0_G, phase_1_G, phase_2_G]) + 1.0)\n",
    "\tT_position = max([phase_0_T, phase_1_T, phase_2_T]) / (min([phase_0_T, phase_1_T, phase_2_T]) + 1.0)\n",
    "\n",
    "\tfickett_score += look_up_content_prob(A_content, 'A', content_para, content_prob, content_weight)\n",
    "\tfickett_score += look_up_content_prob(C_content, 'C', content_para, content_prob, content_weight)\n",
    "\tfickett_score += look_up_content_prob(G_content, 'G', content_para, content_prob, content_weight)\n",
    "\tfickett_score += look_up_content_prob(T_content, 'T', content_para, content_prob, content_weight)\n",
    "\n",
    "\tfickett_score += look_up_position_prob(A_position, 'A', position_para, position_prob, position_weight)\n",
    "\tfickett_score += look_up_position_prob(C_position, 'C', position_para, position_prob, position_weight)\n",
    "\tfickett_score += look_up_position_prob(G_position, 'G', position_para, position_prob, position_weight)\n",
    "\tfickett_score += look_up_position_prob(T_position, 'T', position_para, position_prob, position_weight)\n",
    "\n",
    "\treturn fickett_score\n",
    "\n",
    "\n",
    "def header_fickett_score(foutput):\n",
    "\tfile = open(foutput, 'a')\n",
    "\tfile.write('%s,' % 'nameseq')\n",
    "\tfile.write('%s,' % 'fickett_score-ORF')\n",
    "\tfile.write('%s,' % 'fickett_score-full-sequence')\n",
    "\tfile.write('label')\n",
    "\tfile.write('\\n')\n",
    "\treturn\n",
    "\n",
    "\n",
    "def calculate_sequences(finput, foutput, label_dataset, type_seq):\n",
    "\theader_fickett_score(foutput)\n",
    "\tfor seq_record in SeqIO.parse(finput, 'fasta'):\n",
    "\t\tseq = seq_record.seq\n",
    "\t\tseq = seq.upper()\n",
    "\t\tname_seq = seq_record.name\n",
    "\t\tmeasure_orf = fickett_value_orf(seq, type_seq)\n",
    "\t\tmeasure_full = fickett_value_full_sequence(seq, type_seq)\n",
    "\t\tfile = open(foutput, 'a')\n",
    "\t\tfile.write('%s,' % name_seq)\n",
    "\t\tfile.write('%s,' % str(measure_orf))\n",
    "\t\tfile.write('%s,' % str(measure_full))\n",
    "\t\tfile.write('%s' % str(label_dataset))\n",
    "\t\tfile.write('\\n')\n",
    "\t\tprint('Recorded Sequence: %s' % name_seq)\n",
    "\treturn\n",
    "\n",
    "\n",
    "def FickettScore(finput, foutput, label_dataset):\n",
    "\ttype_seq = 'DNA'\n",
    "\tcalculate_sequences(finput, foutput, label_dataset, type_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Sequence Analyzed!!\n",
      "Sequence Analyzed!!\n",
      "Sequence Analyzed!!\n",
      "Sequence Analyzed!!\n",
      "Sequence Analyzed!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Recorded Sequence!!!\n",
      "Dataset res.fasta: Found File\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Computation time 0.06989479064941406 senconds\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n",
      "Recorded Sequence: BA000007.3\n"
     ]
    }
   ],
   "source": [
    "ExtractionTechniques(\"res.fasta\", 'res_1.csv', 'dnc')\n",
    "ExtractionTechniques(\"res.fasta\", 'res_1.csv', 'tnc')\n",
    "FourierClass(\"res.fasta\", 'res_1.csv', 'mRNA')\n",
    "EntropyClass(\"res.fasta\", 'res_1.csv')\n",
    "AccumulatedNucleotideFrequency(\"res.fasta\", 'res_1.csv', '')\n",
    "CodingClass(\"res.fasta\", 'res_1.csv', 'DNA')\n",
    "FickettScore(\"res.fasta\", 'res_1.csv', 'DNA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PGAMenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
